{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36cca3de",
   "metadata": {},
   "source": [
    "# End-to-End Auto ML Workflow with Your Own StyleGAN2 Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a205a9",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e818a",
   "metadata": {},
   "source": [
    "Running this notebook requires permissions in addition to the normal SageMakerFullAccess permissions. This is because it creates an Lambda Function and new repositories in Amazon ECR. For simplicity of illustration, you can just add the following managed policies to the notebook instance role: <em><strong>AmazonEC2ContainerRegistryFullAccess</strong></em> and <em><strong>AmazonSageMakerPipelinesIntegrations</strong></em>.\n",
    "\n",
    "The Lambda function also needs an IAM role that allows it to deploy a SageMaker Endpoint. The role ARN must be provided in the LambdaStep.  For simplicity of illustration, you can just add the managed policy <em><strong>SageMakerFullAccess</strong></em> to the Lambda Function role.\n",
    "\n",
    "Please remember you should always use IAM policies with least privileges as per AWS IAM best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2c160e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "6724852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "account_id = sagemaker_session.account_id()\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34f2ab4",
   "metadata": {},
   "source": [
    "## Data Download and Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4f62e5",
   "metadata": {},
   "source": [
    "Please visit the original dataset on Kaggle [here](https://www.kaggle.com/datasets/splcher/animefacedataset?resource=download) and download the data in file format(.jpg) to the default_bucket with the prefix of \"My-StyleGAN2-Pipeline/animeface\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da7f0b",
   "metadata": {},
   "source": [
    "## Training Image Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c13d0a",
   "metadata": {},
   "source": [
    "Clone the original StyleGAN2 Git repo to local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c1a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734b260",
   "metadata": {},
   "source": [
    "Let's print the training_loop.py, we need to modify the original training_loop.py so that whenever it saves a checkpoint, it also updates the model in the directory that will be saved to S3 as final result.  You can refer to the <em><strong>training_loop_modified.py</strong></em> directly and replace the original <em><strong>stylegan2-ada-pytorch/training/training_loop.py</strong></em> or you can make the changes yourself.\n",
    "\n",
    "Mainly, just make the following changes:\n",
    "\n",
    "<strong>original:</strong>\n",
    "\n",
    "if rank == 0:\n",
    "\n",
    "    with open(snapshot_pkl, 'wb') as f:\n",
    "        pickle.dump(snapshot_data, f)\n",
    "\n",
    "<strong>new:</strong>\n",
    "\n",
    "if rank == 0:\n",
    "\n",
    "    with open(snapshot_pkl, 'wb') as f:\n",
    "       pickle.dump(snapshot_data, f)\n",
    "\n",
    "    with open(model_pkl, 'wb') as f:\n",
    "       pickle.dump(snapshot_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat stylegan2-ada-pytorch/training/training_loop.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4dc04f",
   "metadata": {},
   "source": [
    "Then let's build the image locally and then push to ECR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05114321",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=mystylegan2\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Get the login command from ECR in order to pull down the SageMaker PyTorch image\n",
    "$(aws ecr get-login --registry-ids 763104351884 --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} . --build-arg REGION=${region}\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d5861",
   "metadata": {},
   "source": [
    "Let's print the training image name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "3623e9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'357224784104.dkr.ecr.us-west-2.amazonaws.com/mystylegan2:latest'"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_name='mystylegan2'\n",
    "stylegan2_image=\"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account_id, region, algorithm_name)\n",
    "stylegan2_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf78d9c",
   "metadata": {},
   "source": [
    "## Define Parameters and Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "819ed02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d4023",
   "metadata": {},
   "source": [
    "#### Process Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "adb959cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_input_data_uri = 's3://{}/My-StyleGAN2-Pipeline/animeface/'.format(default_bucket)\n",
    "process_input_data_path = ParameterString(name=\"ProcessInput\",default_value=process_input_data_uri,)\n",
    "process_instance_count = ParameterInteger(name=\"ProcessInstanceCount\",default_value=1)\n",
    "process_instance_type = ParameterString(name=\"ProcessInstancetType\",default_value='ml.m5.xlarge',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888a8b4",
   "metadata": {},
   "source": [
    "#### Train Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "8eab9ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = stylegan2_image\n",
    "output_uri = 's3://{}/My-StyleGAN2-Pipeline/Model'.format(default_bucket)\n",
    "checkpoint_uri = 's3://{}/My-StyleGAN2-Pipeline/checkpoints'.format(default_bucket)\n",
    "\n",
    "train_instance_count = ParameterInteger(name=\"TrainInstanceCount\",default_value=1)\n",
    "train_instance_type = ParameterString(name=\"TrainInstancetType\",default_value='ml.p3.2xlarge',)\n",
    "train_checkpoint_path = ParameterString(name=\"TrainCheckpointPath\",default_value=checkpoint_uri)\n",
    "train_output_path = ParameterString(name=\"TrainOutputlPath\",default_value=output_uri)# we write the final model to the same S3 directory as the inferencing source codes\n",
    "train_image = ParameterString(name=\"TrainImage\",default_value=image_uri,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b33ba6",
   "metadata": {},
   "source": [
    "#### Inference Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "e49e2624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload the inference code to S3.  \n",
    "source_code_uri = sagemaker_session.upload_data('stylegan2-ada-pytorch', key_prefix='My-StyleGAN2-Pipeline/Inference')\n",
    "#Upload a test image\n",
    "inference_img_uri = sagemaker_session.upload_data('test.png', key_prefix='My-StyleGAN2-Pipeline/InferenceImg')\n",
    "\n",
    "inference_code_path = ParameterString(name=\"InferenceCodePath\",default_value=source_code_uri)\n",
    "inference_image_path = ParameterString(name=\"InferenceImgPath\",default_value=inference_img_uri)\n",
    "inference_instance_count = ParameterInteger(name=\"InferenceInstanceCount\",default_value=1)\n",
    "inference_instance_type = ParameterString(name=\"InferenceInstancetType\",default_value='ml.g4dn.2xlarge',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c55b6ad",
   "metadata": {},
   "source": [
    "## Define Pipeline Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "777638aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "pipeline_session = PipelineSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc7312a",
   "metadata": {},
   "source": [
    "#### Define Processing Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b6240",
   "metadata": {},
   "source": [
    "Preprocessing the animeface dataset into format that fits StyleGAN2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "15bf02f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "# Configure Processor\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=process_instance_type,\n",
    "    instance_count=process_instance_count,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Configure ProcessingStep\n",
    "step_process = ProcessingStep(\n",
    "    name=\"stylegan2Process\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "      ProcessingInput(source=process_input_data, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "      ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\")\n",
    "    ],\n",
    "    ## Processing Arguments\n",
    "    job_arguments=['--source', '/opt/ml/processing/input/',\n",
    "                   '--dest','/opt/ml/processing/train/animeface.zip',\n",
    "                   '--width', '256',\n",
    "                   '--height','256',],\n",
    "    code=\"code_pipeline/dataset_tool.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a5c1b",
   "metadata": {},
   "source": [
    "#### Define Training Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f5afc",
   "metadata": {},
   "source": [
    "Define the training step.  Here we are using the training image we build earlier.  All the checkpoints will be saved to /opt/ml/checkpoints on the training instance, and will be synced with the checkpoint_s3_uri we specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "1eb93a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# Configure training parameters\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "params = {\"data\": \"/opt/ml/input/data/train/animeface.zip\",\n",
    "                   \"gpus\": 1,\n",
    "                   \"augpipe\": \"bg\",\n",
    "                   \"gamma\": 10,\n",
    "                   \"cfg\": \"paper256\", \n",
    "                   \"mirror\": 1, \n",
    "                   \"snap\": 10,\n",
    "                   \"metrics\": \"none\",\n",
    "                   \"kimg\": 1,\n",
    "                   \"outdir\": \"/opt/ml/checkpoints\"}\n",
    "hyperparameters = json_encode_hyperparameters(params)\n",
    "\n",
    "# Configure the estimator\n",
    "estimator_stylegan2 = Estimator(\n",
    "    role=role,\n",
    "    image_uri=train_image,\n",
    "    train_instance_count=train_instance_count,\n",
    "    train_instance_type=train_instance_type,\n",
    "    hyperparameters=hyperparameters,\n",
    "    disable_profiler=True,\n",
    "    checkpoint_s3_uri=train_checkpoint_path,\n",
    "    checkpoint_local_path='/opt/ml/checkpoints',\n",
    "    output_path= train_output_path,\n",
    ")\n",
    "\n",
    "# Configure Training Step\n",
    "step_train = TrainingStep(\n",
    "    name=\"stylegan2train\",\n",
    "    estimator = estimator_stylegan2,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri, \n",
    "                               content_type = 'application/x-image'),\n",
    "    },\n",
    "    depends_on = [step_process],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f936a0",
   "metadata": {},
   "source": [
    "#### Define Inference Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19f412",
   "metadata": {},
   "source": [
    "Define processing step for batch inference with trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "546e4e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it.\n"
     ]
    }
   ],
   "source": [
    "#Initialize the PyTorchProcessor\n",
    "pytorch_processor = PyTorchProcessor(\n",
    "    framework_version='1.10.2',\n",
    "    role=get_execution_role(),\n",
    "    instance_type=inference_instance_type,\n",
    "    instance_count=inference_instance_count,\n",
    "    base_job_name='stylegan2_batch_inference',\n",
    "    py_version = 'py38'\n",
    ")\n",
    "\n",
    "# Configure ProcessingStep\n",
    "step_process_inference = ProcessingStep(\n",
    "    name=\"stylegan2Inference\",\n",
    "    processor=pytorch_processor,\n",
    "    inputs=[\n",
    "      # input 1: source code \n",
    "      ProcessingInput(source=inference_code_path,destination=\"/opt/ml/processing/input\"),\n",
    "      # input 2: trained model\n",
    "      ProcessingInput(source=step_train.properties.ModelArtifacts.S3ModelArtifacts,destination=\"/opt/ml/processing/model\"),\n",
    "      # input 3: test image\n",
    "      ProcessingInput(source=inference_image_path,destination=\"/opt/ml/processing/data\")\n",
    "    ],\n",
    "    outputs=[\n",
    "      ProcessingOutput(output_name=\"result\", source=\"/opt/ml/processing/output/test\")\n",
    "    ],\n",
    "    code=\"code_pipeline/inference.sh\",\n",
    "    depends_on=[step_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c94919",
   "metadata": {},
   "source": [
    "#### Define Notification Lambda Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "dba874e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lambda_deployer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda_deployer.py\n",
    "\n",
    "\"\"\"\n",
    "This Lambda function sents Email to SNS Topic end users once the inference is complete and notify them the output directory on S3.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\" \"\"\"\n",
    "    sns_client = boto3.client(\"sns\")\n",
    "  \n",
    "    output_s3_dir = event[\"output_s3_dir\"]\n",
    "    msg = 'The Inference is done!  The output has been stored at: '+str(output_s3_dir)\n",
    "    response = sns_client.publish(\n",
    "    TopicArn='<Your Topic Arn Here>',\n",
    "    Message=msg,\n",
    "    Subject='StyleGAN2 Inference',\n",
    ")\n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(\"Message Sent!\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "0d2a66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Lambda Step\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "\n",
    "function_name = \"StyleGAN2_pipeline_callback\"\n",
    "\n",
    "# Lambda helper class can be used to create the Lambda function\n",
    "func = Lambda(\n",
    "    function_name=function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=\"lambda_deployer.py\",\n",
    "    handler=\"lambda_deployer.lambda_handler\",\n",
    "    timeout=600,\n",
    "    memory_size=10240,\n",
    ")\n",
    "\n",
    "# Lambda Step Input\n",
    "output_s3_dir = step_process_inference.properties.ProcessingOutputConfig.Outputs[\"result\"].S3Output.S3Uri\n",
    "# Lambda Step Output\n",
    "output_param_1 = LambdaOutput(output_name=\"statusCode\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_2 = LambdaOutput(output_name=\"body\", output_type=LambdaOutputTypeEnum.String)\n",
    "\n",
    "step_lambda = LambdaStep(\n",
    "    name=\"stylegan2Notification\",\n",
    "    lambda_func=func,\n",
    "    inputs={\n",
    "        \"output_s3_dir\": output_s3_dir,\n",
    "    },\n",
    "    outputs=[output_param_1, output_param_2],\n",
    "    depends_on=[step_process_inference]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f9e86",
   "metadata": {},
   "source": [
    "#### Execute Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "8b53e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"stylegan2pipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[process_input_data_path, \n",
    "                process_instance_count, \n",
    "                process_instance_type, \n",
    "                train_instance_count, \n",
    "                train_instance_type, \n",
    "                train_checkpoint_path, \n",
    "                train_output_path,\n",
    "                train_image,\n",
    "                inference_image_path,\n",
    "                inference_code_path,\n",
    "                inference_instance_count,\n",
    "                inference_instance_type\n",
    "               ],\n",
    "    steps=[step_process, step_train, step_process_inference, step_lambda],\n",
    ")\n",
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e8142f",
   "metadata": {},
   "source": [
    "List all the steps that has been executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a6241",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9440f13",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e273d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "def delete_sagemaker_pipeline(sm_client, pipeline_name):\n",
    "    try:\n",
    "        sm_client.delete_pipeline(\n",
    "            PipelineName=pipeline_name,\n",
    "        )\n",
    "        print(\"{} pipeline deleted\".format(pipeline_name))\n",
    "    except Exception as e:\n",
    "        print(\"{} \\n\".format(e))\n",
    "        return\n",
    "    \n",
    "delete_sagemaker_pipeline(sm_client, pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8dbf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
